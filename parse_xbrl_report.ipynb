{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c3c5ec-70a8-4541-9cfc-fee77a586317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Tag\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from tqdm.std import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafa3a97-a8f6-4481-8395-32d067777428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the text and table data\n",
    "def extract_text(soup):\n",
    "    extracted_data = {}\n",
    "    positive_data = []\n",
    "    negative_data = []\n",
    "    seen_texts = set()\n",
    "\n",
    "    entity_types = ['integerItemType','monetaryItemType','perShareItemType','percentItemType','sharesItemType']\n",
    "    \n",
    "    for element in soup.find_all([\"p\", \"div\", \"span\"]):\n",
    "        text = element.get_text(separator=\" \", strip=True) ## to get the content in the text or table\n",
    "\n",
    "        # to set up the recursive_option parameter based on the content from the text or table, \n",
    "        # if it is from the table, the recursive_option is false, otherwise, it is true.\n",
    "        inside_table_cell = element.find_parent([\"td\", \"th\"]) is not None\n",
    "        if inside_table_cell:\n",
    "            continue\n",
    "\n",
    "        # looking up \"ix:nonFraction\"ï¼Œ and the name has to start with \"us-gaap:\"\n",
    "        numeric_entities = []\n",
    "        seen = {}\n",
    "\n",
    "        # recursive_option is used to determine if looking up all child tags as well as the current tag \"ix:nonfraction\" in a line\n",
    "        # if this line is from the text, we just obtain the \"ix:nonfraction\" in the current \"ix:nonfraction\" tag, so the recyrsive_option is flase\n",
    "        # if this line is from the table, we should obtain all child and current \"ix:nonfraction\" tag\n",
    "        for non_fraction in element.find_all(\"ix:nonfraction\",recursive=False):\n",
    "\n",
    "            # to ensure that it is the last layer of this tag \"ix:nonfraction\"\n",
    "            if not non_fraction.find(\"ix:nonfraction\"):\n",
    "                concept = non_fraction.get(\"name\", \"None\")\n",
    "                value = non_fraction.text.strip().replace(\",\", \"\")\n",
    "\n",
    "                if concept.startswith(\"us-gaap:\"):  # to ensure the concept is from the us gaap**\n",
    "                    if value != \"\": ## filter out some None string\n",
    "                        if (value, concept) not in seen: ## drop duplication\n",
    "                            seen[(value, concept)] = True\n",
    "\n",
    "                            processed_concept = concept.split(\":\")[-1].strip()\n",
    "                            entity_type = taxonomy[processed_concept]\n",
    "                            if entity_type in entity_types:\n",
    "                                numeric_entities.append({\"value\": value, \"type\":entity_type, \"concept\": concept})\n",
    "\n",
    "        \n",
    "        # Only add if (ix:nonFraction and us-gaap concept) is met\n",
    "        if numeric_entities:\n",
    "            if len(text) > 20 and text not in seen_texts:\n",
    "                seen_texts.add(text)\n",
    "                extracted_entry = {\"text\": text}\n",
    "                extracted_entry[\"numeric_entities\"] = numeric_entities\n",
    "                positive_data.append(extracted_entry)\n",
    "        else:\n",
    "            if len(text) > 20 and text not in seen_texts:\n",
    "                extracted_entry = {\"text\": text}\n",
    "                extracted_entry[\"numeric_entities\"] = []\n",
    "                negative_data.append(extracted_entry)\n",
    "    \n",
    "    extracted_data = {\"pos\": positive_data, \"neg\": negative_data}\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_table(soup):\n",
    "    extracted_data = {}\n",
    "    positive_data = []\n",
    "    negative_data = []\n",
    "    seen_texts = set()\n",
    "    entity_types = ['integerItemType','monetaryItemType','perShareItemType','percentItemType','sharesItemType']\n",
    "    \n",
    "    for table in soup.find_all(\"table\"):  # Process each table as a whole\n",
    "        table_rows = []\n",
    "        numeric_entities = []\n",
    "        seen = {}\n",
    "        \n",
    "        for table_row in table.find_all(\"tr\", recursive=False):  # Ensure we only get direct children rows\n",
    "            extracted_cells = []\n",
    "            \n",
    "            for cell in table_row.find_all([\"th\", \"td\"], recursive=False):  # Ensure original order\n",
    "                extracted_text_parts = []\n",
    "                \n",
    "                for sub_element in cell.find_all([\"p\", \"div\", \"span\"], recursive=True):\n",
    "                    extracted_text_parts.append(sub_element.get_text(separator=\" \", strip=True))\n",
    "                    \n",
    "                    for non_fraction in sub_element.find_all(\"ix:nonfraction\", recursive=True):\n",
    "                        concept = non_fraction.get(\"name\", \"None\")\n",
    "                        value = non_fraction.text.strip().replace(\",\", \"\")\n",
    "                        \n",
    "                        if concept.startswith(\"us-gaap:\") and value:\n",
    "                            if value != \"\": ## filter out some None string\n",
    "                                if (value, concept) not in seen: ## drop duplication\n",
    "                                    seen[(value, concept)] = True\n",
    "        \n",
    "                                    processed_concept = concept.split(\":\")[-1].strip()\n",
    "                                    entity_type = taxonomy[processed_concept]\n",
    "                                    if entity_type in entity_types:\n",
    "                                        numeric_entities.append({\"value\": value, \"type\":entity_type, \"concept\": concept})\n",
    "                \n",
    "                extracted_text = \" \".join(extracted_text_parts) if extracted_text_parts else cell.get_text(separator=\" \", strip=True)\n",
    "                extracted_cells.append(f\"<{cell.name}>{extracted_text}</{cell.name}>\")\n",
    "            \n",
    "            table_rows.append(f\"<tr>{''.join(extracted_cells)}</tr>\")\n",
    "        \n",
    "        table_text = \"\".join(table_rows)\n",
    "        \n",
    "        # if table_text and table_text not in seen_texts:\n",
    "        #     seen_texts.add(table_text)\n",
    "        #     extracted_entry = {\"text\": f\"<table>{table_text}</table>\"}\n",
    "        #     if numeric_entities:\n",
    "        #         extracted_entry[\"numeric_entities\"] = numeric_entities\n",
    "        #         positive_data.append(extracted_entry)\n",
    "        #     else:\n",
    "        #         extracted_entry[\"numeric_entities\"] = []\n",
    "        #         negative_data.append(extracted_entry)\n",
    "\n",
    "        if numeric_entities:\n",
    "            if table_text and table_text not in seen_texts:\n",
    "                seen_texts.add(table_text)\n",
    "                extracted_entry = {\"text\": f\"<table>{table_text}</table>\"}\n",
    "                extracted_entry[\"numeric_entities\"] = numeric_entities\n",
    "                positive_data.append(extracted_entry)\n",
    "        else:\n",
    "            if table_text and table_text not in seen_texts:\n",
    "                extracted_entry = {\"text\": f\"<table>{table_text}</table>\"}\n",
    "                extracted_entry[\"numeric_entities\"] = []\n",
    "                negative_data.append(extracted_entry)\n",
    "    \n",
    "    extracted_data = {\"pos\": positive_data, \"neg\": negative_data}\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43068452-33c7-455b-8297-61d39014af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the taxonomy dictionary\n",
    "taxomony_path = \"taxonomy/us-gaap-2024_taxonomy.json\"\n",
    "with open(taxomony_path, \"r\") as f:\n",
    "    taxonomy = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044d46c4-deec-4f53-9e8d-f58f3af017ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filefolder = [os.path.join(\"report_data_for_bert/\", d) for d in os.listdir(\"report_data_for_bert/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1195812-cd4a-4085-adee-7ca384074fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['report_data_for_bert/0000766704-25-000009-xbrl',\n",
       " 'report_data_for_bert/0000064803-25-000007-xbrl',\n",
       " 'report_data_for_bert/0001141391-25-000011-xbrl',\n",
       " 'report_data_for_bert/0001628280-25-005002-xbrl',\n",
       " 'report_data_for_bert/.ipynb_checkpoints',\n",
       " 'report_data_for_bert/0001013857-25-000024-xbrl',\n",
       " 'report_data_for_bert/0000906163-25-000011-xbrl',\n",
       " 'report_data_for_bert/0000732717-25-000013-xbrl',\n",
       " 'report_data_for_bert/0000045012-25-000010-xbrl',\n",
       " 'report_data_for_bert/0001522727-25-000010-xbrl',\n",
       " 'report_data_for_bert/0000021175-25-000008-xbrl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filefolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1aeb64-8dd2-4527-baa6-bcbaa957ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/tmp/ipykernel_2402823/867599252.py:15: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(content, \"lxml\")\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 4/11 [00:10<00:14,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report_data_for_bert/.ipynb_checkpoints\n",
      "skip this folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:16<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# reading the ixbrl file\n",
    "\n",
    "text_datas = []\n",
    "table_datas = []\n",
    "\n",
    "for file in tqdm(filefolder):\n",
    "    try:\n",
    "        xsd_file = glob.glob(os.path.join(file, \"*.xsd\"))[0]\n",
    "        base_name = os.path.splitext(os.path.basename(xsd_file))[0]\n",
    "        htm_file = os.path.join(file, f\"{base_name}.htm\")\n",
    "        try:    \n",
    "            with open(htm_file, \"r\", encoding=\"utf-8\") as file:\n",
    "                content = file.read()\n",
    "            # parsing HTML\n",
    "            soup = BeautifulSoup(content, \"lxml\")\n",
    "            text_data = extract_text(soup)\n",
    "            table_data = extract_table(soup)\n",
    "        \n",
    "            text_datas.append(text_data)\n",
    "            table_datas.append(table_data)\n",
    "        except:\n",
    "            print(htm_file)\n",
    "    except:\n",
    "        print(file)\n",
    "        print(\"skip this folder\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a247d1ea-c879-4bb4-b3ae-0ed1a06d4b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bda33832-dfdd-4315-a30f-a0529181b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"annotation/simple_data/for_bert_training_annotation.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "    \"text_data\": text_datas,\n",
    "    \"table_data\": table_datas\n",
    "}, f,indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea606f-dceb-4fe8-a762-da10fbf590a6",
   "metadata": {},
   "source": [
    "## statistic entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c18df9b-6b0c-4b3c-a19e-f6d9765856a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b75f6fb-6ad7-42fb-8486-2eaa1eed48f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eea8535-1499-4a6c-88e0-f6ffeb2283e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d1a218-5adb-40be-a0ee-7ed492f0e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in text_datas:\n",
    "    for entity in line.get(\"numeric_entities\"):\n",
    "        entity_types.add(entity.get(\"type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bfc42a-f3cc-49ec-94bc-25c46a9fab25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'integerItemType',\n",
       " 'monetaryItemType',\n",
       " 'perShareItemType',\n",
       " 'percentItemType',\n",
       " 'sharesItemType'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c07fb-aa73-4ce3-8fb2-9b96929eb6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter-citation",
   "language": "python",
   "name": "my-jupyter-citation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
